{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction t Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter...predicting a number"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d5ced78528659"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae0141e0bd93e5ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating data to view and fit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a4537450b2b7090"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating features (inputs)\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b83d29a20c6f4cfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input and Output shapes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c046dd3e884c488"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb63ded75e26719"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = X.shape\n",
    "output_shape = y.shape\n",
    "input_shape, output_shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62805f0a56a668f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Turn our Numpy arrays into Tensor\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24589007b270e7df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f6fb8999ffca350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(X,y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeca3c4a74b31267"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d82cc3233a123b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae is short for measure absolute error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6852cc9eb92b4759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checkout X and y\n",
    "X, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737ce324f33218cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([18.0])\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e649fb5f7e219db5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeb93cfba3984d19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's rebuild our model\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe0a731f9cd7aedb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e0a7b2bde9b233"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see if our models's prediction has improved\n",
    "model.predict([18.0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd9ec1f903d4e442"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see if we can make another to improve our model\n",
    "\n",
    "# 1. Create the model (with hidden layer with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f294593b265431b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see if our models's prediction has improved\n",
    "model.predict([18.0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0924e554afceffb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluting a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building a neural networks is:\n",
    "\n",
    "```\n",
    "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d831fde983abb033"
  },
  {
   "cell_type": "markdown",
   "source": [
    "when it comes to evaluation...there are 3 words you should memorize:\n",
    "\n",
    "> \"Visualize, visualize, visualize\"\n",
    "\n",
    "It's a good idea to visualize:\n",
    "* The data - what data are working with? what does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The predictions of the model - how do the predictions of a model line up against the ground truth ( the originals labels)?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "234802e8b7574c19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100,100, 4)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16d855a8a21d5759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad0c6e3f71b0eac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57a0f53b88cf44c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The 3 sets...\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available.\n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b13e93a47947b8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "708ea0ae161c0180"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40]\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:]\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d21e76bd6e11f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now we've got our data in training and test sets...let's visualize it again!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ae7ba288b1cbba9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c='g', label=\"Testing data\")\n",
    "# Show a legend\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e98ed1d27d9d011"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
