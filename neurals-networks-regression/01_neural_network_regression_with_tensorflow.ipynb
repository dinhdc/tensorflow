{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction t Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter...predicting a number"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d5ced78528659"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae0141e0bd93e5ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating data to view and fit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a4537450b2b7090"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating features (inputs)\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b83d29a20c6f4cfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input and Output shapes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c046dd3e884c488"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb63ded75e26719"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = X.shape\n",
    "output_shape = y.shape\n",
    "input_shape, output_shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62805f0a56a668f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Turn our Numpy arrays into Tensor\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24589007b270e7df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f6fb8999ffca350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(X,y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeca3c4a74b31267"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d82cc3233a123b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae is short for measure absolute error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6852cc9eb92b4759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checkout X and y\n",
    "X, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737ce324f33218cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([18.0])\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e649fb5f7e219db5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeb93cfba3984d19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's rebuild our model\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe0a731f9cd7aedb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e0a7b2bde9b233"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see if our models's prediction has improved\n",
    "model.predict([18.0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd9ec1f903d4e442"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see if we can make another to improve our model\n",
    "\n",
    "# 1. Create the model (with hidden layer with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f294593b265431b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see if our models's prediction has improved\n",
    "model.predict([18.0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0924e554afceffb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluting a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building a neural networks is:\n",
    "\n",
    "```\n",
    "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d831fde983abb033"
  },
  {
   "cell_type": "markdown",
   "source": [
    "when it comes to evaluation...there are 3 words you should memorize:\n",
    "\n",
    "> \"Visualize, visualize, visualize\"\n",
    "\n",
    "It's a good idea to visualize:\n",
    "* The data - what data are working with? what does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The predictions of the model - how do the predictions of a model line up against the ground truth ( the originals labels)?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "234802e8b7574c19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100,100, 4)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16d855a8a21d5759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad0c6e3f71b0eac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57a0f53b88cf44c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The 3 sets...\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available.\n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b13e93a47947b8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "708ea0ae161c0180"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40]\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:]\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d21e76bd6e11f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now we've got our data in training and test sets...let's visualize it again!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ae7ba288b1cbba9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c='g', label=\"Testing data\")\n",
    "# Show a legend\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e98ed1d27d9d011"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's have a look at how to build a neural network for our data\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# # 3. Fit the model\n",
    "# model.fit(X_train, y_train, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb4168a930a5b03c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ea9d9098a9c57f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52318216877b073"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by defining the input_shape argument\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"model_1\")\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a16075b074508b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f86bee93b80ff45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Total params - total number of parameters in the model.\n",
    "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
    "* Non-trainable parameter - these aren't updated during training (this is typical when you bring in already learn patterns or parameters from other model during **transfer learning**)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c90f88245f040d90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a599e056db5a3eef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get a summary of our model\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e34de72a85b868a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model=model, show_shapes=True, to_file=\"model.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2f3b0042bfe22a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing our model's prediction\n",
    "\n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
    "\n",
    "Often you'll see this in the form of `y_set` or `y_true` versus `y_pred` (ground truth versus your model's predictions)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d85923fdbed2739d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7827ad20bdc4808"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd6715cbcff63bda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's create a plotting function\n",
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=y_pred):\n",
    "    \"\"\"\n",
    "    PLots training data, test data and compares predictions to ground truth label\n",
    "    :param train_data: list of training data\n",
    "    :param train_labels: \n",
    "    :param test_data: \n",
    "    :param test_labels: \n",
    "    :param predictions: \n",
    "    :return: show the legend relation between train_data, train_labels and test_data, test_labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "    # Plot testing data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "    # Plot model's predictions in red\n",
    "    plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
    "    # Show the legend\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d72e7d72cb7e1ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_predictions(train_data=X_train, \n",
    "                 train_labels=y_train, \n",
    "                 test_data=X_test, \n",
    "                 test_labels=y_test, \n",
    "                 predictions=y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a86f97828e9ef858"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating our model's predictions with regression evaluation metrics\n",
    "\n",
    "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
    "\n",
    "Since we're working on a regression, two of the main metrics:\n",
    "* MAE - mean absolute error, \"on average, how wrong is each of my model's predictions\"\n",
    "* MSE - mean square error, \"square the average errors\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6744fa81053ae66c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the test\n",
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79795da68408e70d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c9308da80f1c561"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "760721ceeb327398"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
    "mae"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56660c7012b74741"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.squeeze(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a541cdffd3c2d98d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=tf.squeeze(y_pred))\n",
    "mae"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c44ffb60b4f4cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the mean square error\n",
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=tf.squeeze(y_pred))\n",
    "mse"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b229cc099f06580"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make some functions to reuse MAE and MSE\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_true, y_pred=tf.squeeze(y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fd6470e8d3350a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running experiments to improve our model\n",
    "\n",
    "\n",
    "```Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> tweak it > fit it -> evaluate it...```\n",
    "\n",
    "1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
    "2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
    "3. Train for longer - give your model more of a chance to find patterns in the data\n",
    "\n",
    "Let's do 3 modelling experiments:\n",
    "\n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "2. `model_2` - 2 layers, trained for 100 epochs.\n",
    "3. `model_3` - 2 layers, trained for 500 epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f763540d49ae259d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Build `model_1`**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c545cdef0337626"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de29a3e325a496df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34834412d58d2410"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, y_preds_1)\n",
    "mse_1 = mse(y_test, y_preds_1)\n",
    "mae_1, mse_1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c070f245c1d39e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Build `model_2`**\n",
    "\n",
    "* 2 dense layers, trained for 100 epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9ad305ebd263c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24589cd27cc1ef3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make and plot predictions of model 2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b25b6d218b74f897"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, y_preds_2)\n",
    "mse_2 = mse(y_test, y_preds_2)\n",
    "mae_2, mse_2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b96febeefdeda641"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Build `model_3`**\n",
    "\n",
    "* 2 layers, trained for 500 epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a583dda60e46e109"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a28904132d03bd77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make and plot some predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cb3865ab71ab078"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate model_3 evaluation metrics\n",
    "mae_3 = mae(y_test, y_preds_3)\n",
    "mse_3 = mse(y_test, y_preds_3)\n",
    "mae_3, mse_3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53a5cb8f93d406cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparing the results of our experiments\n",
    "\n",
    "We're run a few experiments, let's compare the results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "392238906f3d427c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's compare our model's results using a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "all_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf1e8c784f0b258a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like `model_2` performed the best..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f156b2f122096eea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f5f1b3a6e4bf9af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tracking your experiments\n",
    "\n",
    "One really good habit in machine learning modelling is to track the results of your experiments.\n",
    "\n",
    "And when doing so, it can be tedious if you're running lots of experiments.\n",
    "\n",
    "Luckily, there are tools to help us!\n",
    "\n",
    "* TensorBoard - a component of the TensorFlow library to help track modelling experiments \n",
    "* Weights & Biases - a tool for tracking all of kinds of machine learning experiments (plugs straight into TensorBoard)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc14ca93c6c6e4d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving our model\n",
    "\n",
    "Saving our models allow us to use them outside such as in a web application or a mobile app.\n",
    "\n",
    "There are two main formats we can save our model's too:\n",
    "\n",
    "1. The SavedModel format\n",
    "2. The HDF5 format"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d902015264863f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save model using  the SavedModel format\n",
    "model_2.save(\"best_model_SavedModel_format\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61240dc2975263bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save model using the HDF5 format\n",
    "model_2.save(\"best_model_HDF5_format.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "766cd5b361902085"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading a saved model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e42dbc257f9dbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load in the SavedModel format model\n",
    "loaded_SavedModel_format = tf.keras.models.load_model('best_model_SavedModel_format')\n",
    "loaded_SavedModel_format.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "107f69f1ee9adee5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce513c6e49b96b44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare model_2 prediction with SavedModel format predition\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
    "model_2_preds == loaded_SavedModel_format_preds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3568a908774ce52d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load in model using HDF5 format\n",
    "loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "804d1b769f65396d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare the MAE of model_2 preds and loaded_SavedModel_preds\n",
    "mae(y_true=y_test, y_pred=model_2_preds) == mae(y_true=y_test, y_pred=loaded_SavedModel_format_preds)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a43ea218818cc5b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check to see if loaded .h5 model predictions match model_2\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e8973fa5e9b6605"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A larger example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23f60cef1db30064"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imported required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c289c0a4a291473"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in the insurance dataset\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "396af8df9eb7e859"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's try one-hot encode our DataFrame into numerical\n",
    "insurance_one_hot = pd.get_dummies(insurance, dtype=int)\n",
    "insurance_one_hot.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1cecceda9d5a12c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create X and y values (features and labels)\n",
    "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
    "y = insurance_one_hot[\"charges\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0ddf274c9146e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# View X\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db56bd1dc41be88c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# View y\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b3b1f8207b66e81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "len(X), len(X_train), len(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382cbe7faefb5255"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build a neural network \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(loss=tf.keras.losses.mae,\n",
    "                        optimizer=tf.keras.optimizers.SGD(),\n",
    "                        metrics=[\"mae\"])\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(tf.constant(X_train), tf.constant(y_train), epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "585ad62d6835ef7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "insurance_model.evaluate(tf.constant(X_test), tf.constant(y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7948164bfcf709"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb61c0c33bbaa92d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Right now it looks like our model isn't performing too well...let's try and improve it\n",
    "\n",
    "To (try) improve our model, we'll run 2 experiments:\n",
    "1. Add an extra layer with more hidden units nad use the Adam optimizer\n",
    "2. Train for longer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e521557e1e342dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(tf.constant(X_train), tf.constant(y_train), epochs=100, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99d21f767b53a9b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate new model\n",
    "insurance_model_2.evaluate(tf.constant(X_test), tf.constant(y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "571ad3978718329b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "insurance_model.evaluate(tf.constant(X_test), tf.constant(y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42d558b3f7459fe5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1.Create a model\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. FIt the model\n",
    "history = insurance_model_3.fit(tf.constant(X_train), tf.constant(y_train), epochs=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9424c9ebb99b8b44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate our third model\n",
    "insurance_model_3.evaluate(tf.constant(X_test), tf.constant(y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da72c9efb346387b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "insurance_model.evaluate(tf.constant(X_test), tf.constant(y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "343781ee70c78da6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot history (also known as a loss curve or a training curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7214ac2c013fe06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing data (normalization and standardization)\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization.\n",
    "\n",
    "If you're not sure on which to use, you could try both and see which performs better."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "add5fd3b39c4a7ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in the insurance dataframe\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8902510df35c6224"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To prepare our data, we can borrow a few classes from Scikit-Learn."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2f5baf592ca5129"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in these columns into zero and one\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X & y values\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the column transformers to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)\n",
    "X_train_normal[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a495f2a27ce6a2e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_normal.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bbcc170aabb590c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build a neural network model to fit on our normalize data\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3126b2ded5ac883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate our insurance model trained on normalized data\n",
    "insurance_model_4.evaluate(X_test_normal, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "831ba698400758b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "586229ff60507dd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
